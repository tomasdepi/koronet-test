
## Koronet

Following there are some consideration and reasons behind some decisions

### WebApp

Despite being Python my strongest programming language, I chose Golang mostly for a personal challenge but also for it's capabilities to generate small binaries, being perfect for containerized applications (unlike other languages, doesn't need an interpreter or a runtime)

Since the challange involves the proposal of a high level monitoring diagram, I added a `/metrics` endpoint that returns prometheus metrics-wise output, so the diagram makes more sense

Although the webapp is quite small and everything can be done inside one file, I decided breaking it down into three packages `core`, `cache` and `rds`, this grants reusability, can scale individually and are easier to test

## Dockerfile
I understand that surely you expected a custom Dockerfile, however I'm using the default Dockerfile generated by `docker init` command, it provides a multi-stage build alongisde lightweigh containers like `alpine`

## Github Actions
I created two pipelines:

1. For tests executions, leveraging the concept of `services` I can spin up a `redis` and a `mysql`, being able to run integration test
2. For building and pushing the docker image into my private dockerhub account. This pipeline has a seconday jobs which is disabled by default, being it's responsability to deploy the new image into `ECS`. The ECS task definition points to `lastest` image tag, so by overriding the lastest tag, I only need to force a new deployment. I understand that using commit tags would be better, however that approach would involved the recreation of the task definition, increasing the difficulty of the challange and it's scope 


## Terraform

* In `providers.tf` I'm mocking aws credentials and skipping validations only to be able to run `terraform plan`, allowing me to check the plan and detect possible errors
* In `backend.tf` I have defined a S3 backend state with `use_lockfile` (don't need to use dynamodb with this approach), but I commented it out since I do not have access to a AWS account therefore I can not run the code to initizalice the backend
* For the VPC setup I have defined a NAT Gateway per AZ, this is more expensive but provides High Availability in case one AZ goes down. This approach is suitable for production environments
* For `ECS`, I chose using `Fargate` because it's serverless, the another option would be using `EC2` however that involves an operational overhead not useful for the context of the exersice
* Despite I could expose the containers directly, I went for a more production approach, which involved deploying the Task containers into private subnets and then deploying an ALB in public subnet being internet-facing
* I understand that using `ECR` as image registry would be more suitable since we're thinking this exersice with `ECS`, however we're using `dockerhub` so I created a secret in `AWS Secret Manager` and configured the Task Definition to use it to pull the image from my personal and private dockerhub acount
